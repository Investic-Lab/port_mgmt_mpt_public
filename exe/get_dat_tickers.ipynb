{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" NASDAQ 100 and Dow Jones 30 \"\"\"\n",
    "\n",
    "# URLs of the Wikipedia pages containing the list of constituents for each index\n",
    "try:\n",
    "    urls = {\n",
    "        'nasdaq100': 'https://en.wikipedia.org/wiki/NASDAQ-100',\n",
    "        'dow30': 'https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average'\n",
    "    }\n",
    "\n",
    "    # For NASDAQ 100 and Dow Jones 30, you might need to adjust the table index depending on the Wikipedia page structure\n",
    "    nasdaq100_constituents = pd.read_html(urls['nasdaq100'])[4].rename(columns={'Ticker':'Symbol'})\n",
    "    dow30_constituents = pd.read_html(urls['dow30'])[1]  # Adjust the table index if necessary\n",
    "    \n",
    "    \"\"\" Swap columns for Nasdaq 100 \"\"\"\n",
    "    # Swap the values between 'Company' and 'Symbol' columns && Swap the column headers\n",
    "    nasdaq100_constituents[['Symbol', 'Company']] = nasdaq100_constituents[['Company', 'Symbol']]\n",
    "    nasdaq100_constituents.columns = ['Symbol', 'Company', 'GICS Sector', 'GICS Sub-Industry']\n",
    "\n",
    "    # Specify the file name where the data should be written\n",
    "    file_path = \"../dat\"  # Ensure this folder exists or create it before running the code\n",
    "\n",
    "    # Save NASDAQ 100 constituents to a CSV file\n",
    "    nasdaq100_file_name = \"nasdaq100tickers.csv\"\n",
    "    nasdaq100_constituents.to_csv(f\"{file_path}/{nasdaq100_file_name}\", index=False)\n",
    "\n",
    "    # Save Dow Jones 30 constituents to a CSV file\n",
    "    dow30_file_name = \"dow30tickers.csv\"\n",
    "    dow30_constituents.to_csv(f\"{file_path}/{dow30_file_name}\", index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" S&P 500 400 600 - Big Mid Small \"\"\"\n",
    "\n",
    "# URLs of the Wikipedia pages containing the list of constituents for each index\n",
    "try:\n",
    "    urls = {\n",
    "        'sp500': 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies',\n",
    "        'sp400': 'https://en.wikipedia.org/wiki/List_of_S%26P_400_companies',\n",
    "        'sp600': 'https://en.wikipedia.org/wiki/List_of_S%26P_600_companies'\n",
    "    }\n",
    "\n",
    "    constituents = {index: pd.read_html(url)[0] for index, url in urls.items()}\n",
    "\n",
    "    sp500_constituents = constituents['sp500']\n",
    "    sp400_constituents = constituents['sp400']\n",
    "    sp600_constituents = constituents['sp600']\n",
    "\n",
    "    # Concatenate the constituents for each index to get S&P 1500\n",
    "    sp1500_constituents = pd.concat([sp500_constituents, sp400_constituents, sp600_constituents], ignore_index=True)\n",
    "\n",
    "    # Specify the file name where the data should be written\n",
    "    file_path = \"../dat\"  # Corrected the folder name to 'data', please ensure the folder exists or create it\n",
    "    sp1500_file_name = \"sp1500tickers.csv\"\n",
    "    sp1500_constituents.to_csv(f\"{file_path}/{sp1500_file_name}\", index=False)\n",
    "\n",
    "    # If you want to save individual index constituents as separate CSVs\n",
    "    sp500_file_name = \"sp500tickers.csv\"\n",
    "    sp400_file_name = \"sp400tickers.csv\"\n",
    "    sp600_file_name = \"sp600tickers.csv\"\n",
    "    \n",
    "    sp500_constituents.to_csv(f\"{file_path}/{sp500_file_name}\", index=False)\n",
    "    sp400_constituents.to_csv(f\"{file_path}/{sp400_file_name}\", index=False)\n",
    "    sp600_constituents.to_csv(f\"{file_path}/{sp600_file_name}\", index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
